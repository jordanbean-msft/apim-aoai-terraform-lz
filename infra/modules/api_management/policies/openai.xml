<policies>
    <inbound>
        <base />
        <set-backend-service backend-id="aoai-default-load-balanced-pool" />
        <include-fragment fragment-id="setup-correlation-id" />
        <include-fragment fragment-id="entra-id-authentication" />
        <azure-openai-emit-token-metric namespace="AzureOpenAI">
            <dimension name="User ID" />
            <dimension name="Client IP" value="@(context.Request.IpAddress)" />
            <dimension name="API ID" />
            <dimension name="Subscription ID" />
        </azure-openai-emit-token-metric>
        <azure-openai-token-limit tokens-per-minute="{{openai-token-limit-per-minute}}" counter-key="@(context.Subscription.Id)" estimate-prompt-tokens="true" tokens-consumed-header-name="consumed-tokens" remaining-tokens-header-name="remaining-tokens" />
        <include-fragment fragment-id="generate-partition-key" />
        <include-fragment fragment-id="openai-event-hub-logging-inbound" />
        <include-fragment fragment-id="semantic-cache-lookup" />
        <include-fragment fragment-id="ai-foundry-cors" />
    </inbound>
    <backend>
        <retry count="1" interval="0" first-fast-retry="true" condition="@(context.Response.StatusCode == 429 || (context.Response.StatusCode == 503 && !context.Response.StatusReason.Contains("Backend pool") && !context.Response.StatusReason.Contains("is temporarily unavailable")))">
            <forward-request buffer-request-body="true" />
        </retry>
    </backend>
    <outbound>
        <include-fragment fragment-id="semantic-cache-store" />
        <base />
        <set-header name="x-correlation-id" exists-action="override">
            <value>@((string)context.Variables["correlation-id"])</value>
        </set-header>
        <include-fragment fragment-id="openai-event-hub-logging-outbound" />
    </outbound>
    <on-error>
        <base />
    </on-error>
</policies>
